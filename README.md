# Run your Docker containers for free in the cloud and for unlimited time

Having a place other than your own machine to run docker containers can be handy.
It helps you to speed up the development of your personal projects or relieve the
heavy lifting from your machine.  
Recently I was introduced Oracle cloud, and its free tier for an unlimited time.

## Check the supported always free services:

- 2 AMD based Compute VMs with 1/8 OCPU** and 1 GB memory each
- 4 Arm-based Ampere A1 cores and 24 GB of memory usable as one VM or up to 4 VMs
- 2 Block Volumes Storage, 200 GB total
- 10 GB Object Storage - Standard
- 10 GB Object Storage - Infrequent Access
- 10 GB Archive Storage
- Resource Manager: managed Terraform
- 5 OCI Bastions

As you can see they are very generous with their free tier, and we can do a lot
with this.

## Create your remote Docker service

1. Create an Oracle Cloud Infrastructure account (just follow [this link](https://signup.cloud.oracle.com/)).
2. [Install terraform](https://learn.hashicorp.com/tutorials/terraform/install-cli?in=terraform/oci-get-started).
3. [Install OCI CLI](https://docs.oracle.com/en-us/iaas/Content/API/SDKDocs/cliinstall.htm).
4. [Configure OCI credentials](https://learn.hashicorp.com/tutorials/terraform/oci-build?in=terraform/oci-get-started).

As you can suspect by now, we are going to use terraform to provision our Docker service. Basically terraform will create one VM instance as big as the free tear allow us, and let it ready so we can ssh into the machine and with docker ready to start our containers.  

In short, execute following command:

`oci session authenticate`

- Select server in which you registered
- Authenticate with web browser
- Store session profile with a name or `DEFAULT`

5. Checkout this project with the terraform configuration

If you want access OCI compute instance using a (dy.fi) domain name:
6. [Create dy.fi account](https://dy.fi)

Configure variables `dyfi_username`, `dyfi_password` and `dyfi_hostname` in variables.tf.
Check also other variables to get desired compute instance and user names for SSH access.

7. Run `terraform init` and `terraform apply` 

If you get an error like this:

```
timeout -- last error: dial tcp IP_ADDRESS:22: connect: connection refused
```

try to add the id_rsa generated by terraform to your ssh-agent ( `ssh-add id_rsa` ) and run terraform apply one more time.  

If you were able to reach this point, you now have a VM running that you can run whatever you want (check Oracle's terms and conditions for this service). At the end of the process terraform is configured to show the public IP of newly created instance.
What I like to do is to add this to /etc/hosts so I don't need to call it by the IP address.

`ssh_docker-remote` file (generated when `terraform apply` command is executed) in the root of this repository contains configuration which can be added to `~/ssh/config` file:

```
Include /path/to/remote-docker/ssh_docker-remote
```

Connect to the remote server using ssh and run docker ps to check if docker is running as expected.

## Deploying your container

OK, now you want to start running containers there from your local machine, but you also run some containers locally for whatever reason.
So we need to do it in a way that is easy to switch between the two contexts.
Docker has a tool for that embedded on its client, to check the contexts that you have available run:

```
docker context ls 
```

Let's create a context for our remote docker service:

```
docker context create remote --docker "host=ssh://docker@IP_PROVIDED_BY_TERRAFORM"
```

... or if `ssh_docker-remote` is Included in `~/ssh/config` file ...

```
docker context create remote --docker "host=ssh://docker@<Host in ssh_docker-remote file>"
```


Now if you list your contexts again you should see your newly created context. The next step is to switch between contexts:

```
docker context use remote
```

If no errors were reported, now you can run any command that you would normally do locally. To check if it is working try to deploy a nginx container.

```
docker run -d -p 8080:80 nginx 
```
If remote can't be used (for any reason), which happens in WSL environment, you can tell docker explicitly on which context the container should be run.

```
docker --context remote run -d -p 80:80 nginx
```

After this you should be able to open on your browser: http://IP_PROVIDED_BY_TERRAFORM (or http://dyfi_hostname) and you should see the default index.html from docker.

## Conclusion

This project was shamelessly based on [Jérôme Petazzoni's project](https://github.com/jpetazzo/ampernetacle), where he describes how to build a Kubernetes cluster on Oracle infrastructure using the free tier. His project was very helpful to understand terraform and the configuration of Kubernetes. I highly recommend you to check it out.  

I made this spinoff of his project because, it is great to learn how to deploy a K8S cluster, but it was not that useful for me to have it laying around. Docker service is more useful to have it when you are developing.  

And I can see how that can be helpful, especially when your machine is at its limit.ssh

<a href="https://www.buymeacoffee.com/r25b8yt77fh" target="_blank"><img src="https://cdn.buymeacoffee.com/buttons/default-orange.png" alt="Buy Me A Coffee" height="41" width="174"></a>
